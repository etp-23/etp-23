{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM/17ATQR3DFfDm2jKvaAec"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pB597f4WBOSl","executionInfo":{"status":"ok","timestamp":1697636513726,"user_tz":-120,"elapsed":1830,"user":{"displayName":"Aubin Medjaed (Led Zep)","userId":"00879047544357892465"}},"outputId":"90c9c33e-a0e4-46ce-9788-d1c7c724092c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 1 1 1 0 0 1 0 1]\n"," [0 2 0 1 0 1 1 0 1]\n"," [1 0 0 1 1 0 1 1 1]\n"," [0 1 1 1 0 0 1 0 1]]\n","['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"]}],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Sample documents\n","documents = [\n","    \"This is the first document.\",\n","    \"This document is the second document.\",\n","    \"And this is the third one.\",\n","    \"Is this the first document?\"\n","]\n","\n","# Create an instance of CountVectorizer\n","vectorizer = CountVectorizer()\n","\n","# Fit the vectorizer to your documents and transform them into BoW vectors\n","X = vectorizer.fit_transform(documents)\n","\n","# The resulting X is a sparse matrix where each row is a document and each column is a word.\n","# You can convert it to a dense matrix using X.toarray()\n","\n","# Get the vocabulary\n","vocabulary = vectorizer.get_feature_names_out()\n","\n","# Print the BoW vectors and the vocabulary\n","print(X.toarray())\n","print(vocabulary)\n"]},{"cell_type":"markdown","source":["###ChatGPT is your friend (not realy) :"],"metadata":{"id":"7iSZAX2QCMt0"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the CSV file into a DataFrame\n","df = pd.read_csv('first_1000.csv')\n","\n","# Assuming your text data is in a column named 'text_column'\n","text_data = df['text'].tolist()\n"],"metadata":{"id":"HLCVyVCWCUQl","executionInfo":{"status":"ok","timestamp":1697636858440,"user_tz":-120,"elapsed":3,"user":{"displayName":"Aubin Medjaed (Led Zep)","userId":"00879047544357892465"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('punkt')  # Download the necessary data if you haven't already\n","\n","# Tokenize the text data\n","tokenized_data = [word_tokenize(text) for text in text_data]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZShKZ3sUCtib","executionInfo":{"status":"ok","timestamp":1697636872346,"user_tz":-120,"elapsed":1754,"user":{"displayName":"Aubin Medjaed (Led Zep)","userId":"00879047544357892465"}},"outputId":"b0aaad8a-827b-41cc-e73e-243009a628f3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","# Create an instance of CountVectorizer\n","vectorizer = CountVectorizer()\n","\n","# Fit the vectorizer to your tokenized data and transform it into BoW vectors\n","X = vectorizer.fit_transform([' '.join(tokens) for tokens in tokenized_data])\n","\n","# Get the vocabulary\n","vocabulary = vectorizer.get_feature_names_out()\n","\n","# The resulting X is a sparse matrix where each row is a document and each column is a word.\n","# You can convert it to a dense matrix using X.toarray()\n"],"metadata":{"id":"dwtH0g9yCxOF","executionInfo":{"status":"ok","timestamp":1697636899133,"user_tz":-120,"elapsed":327,"user":{"displayName":"Aubin Medjaed (Led Zep)","userId":"00879047544357892465"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Print the BoW vectors and the vocabulary\n","print(X.toarray())\n","print(vocabulary)"],"metadata":{"id":"OMUc67qDC8QQ","executionInfo":{"status":"ok","timestamp":1697636930801,"user_tz":-120,"elapsed":5,"user":{"displayName":"Aubin Medjaed (Led Zep)","userId":"00879047544357892465"}},"outputId":"acd733d6-5805-4517-9dff-a5001cf72708","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n","['00' '000' '04' ... 'zombie' 'zombiefied' 'Â¹assuming']\n"]}]}]}